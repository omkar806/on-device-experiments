{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFvMD8ZBhyXtk/w+PLuGNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkar806/on-device-experiments/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_kr9UWmYOI2l"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain openai langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from datetime import datetime\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import os"
      ],
      "metadata": {
        "id": "alHV5SN8QbqH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting today's date\n",
        "today_date = datetime.today().date()\n",
        "print(today_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdHA3AFyS1vH",
        "outputId": "05d86c7a-05ae-44fc-aa71-30aa73d952b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a pydantic model for getting the exact strcutured json from the input query as we want\n",
        "class Candidate(BaseModel):\n",
        "    entity: str = Field(description=\"The company name mentioned in the query (e.g., Flipkart, Amazon).\")\n",
        "    parameter: str = Field(description=\"The performance metric mentioned in the query (e.g., GMV, revenue, profit)\")\n",
        "    startDate: str = Field(description=f\"The start date of the time period for which the metric is requested. By default If the user query does not explicitly mention the start date.Assume start date to be : Today's date(is {today_date}) minus one year.\")\n",
        "    endDate: str = Field(description=f\"The end date of the time period for which the metric is requested.By default If the user query does not explicitly mention the start date. Assume the end date to be : Today's date(is {today_date}).\")"
      ],
      "metadata": {
        "id": "EnWO5LDKQdzN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"Enter Your OPENAI_API_KEY\"\n",
        "model_name = \"gpt-3.5-turbo-instruct\"\n",
        "temperature = 0.0\n",
        "model = OpenAI(model_name=model_name, temperature=temperature, max_tokens=800)"
      ],
      "metadata": {
        "id": "fmxkPt7BQtyB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_query = input(\"User: \")\n",
        "  parser = PydanticOutputParser(pydantic_object=Candidate)\n",
        "  prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n {format_instructions}\\n {query} \\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "  )\n",
        "  input = prompt.format_prompt(query=user_query)\n",
        "  with get_openai_callback() as cb:\n",
        "      result = model(input.to_string())\n",
        "      #print(result)\n",
        "      print(parser.parse(result))\n",
        "      #print(result)\n",
        "      #print(cb)\n",
        "\n",
        "  # print(output)\n",
        "  # parser.parse(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "j02c2pDHQv62",
        "outputId": "d28a1b80-f5ef-40d6-ea5f-c64b1a380a4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'StringPromptValue' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-809338c94aa3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPydanticOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydantic_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   prompt = PromptTemplate(\n\u001b[1;32m      5\u001b[0m     \u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Answer the user query.\\n {format_instructions}\\n {query} \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'StringPromptValue' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_object= parser.parse(result)\n",
        "dict_object=class_object.__dict__\n",
        "print(type(dict_object))\n",
        "print(dict_object)"
      ],
      "metadata": {
        "id": "8CsuTYeyYY7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
