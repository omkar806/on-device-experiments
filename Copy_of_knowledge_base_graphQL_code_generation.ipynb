{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNICA7Ib/aco+1eLoevVPtU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkar806/on-device-experiments/blob/main/Copy_of_knowledge_base_graphQL_code_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run the below cell to install all the libraries"
      ],
      "metadata": {
        "id": "Akm2iYKs7gx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kr9UWmYOI2l",
        "outputId": "b1ad6f1d-f85c-4c01-a236-5c5cf4f2b1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain openai langchain_openai langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import all the neccessary libraries using the below cell"
      ],
      "metadata": {
        "id": "5kBuWSjB7rmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "alHV5SN8QbqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining a Pydantic Model to extract the exact information for Each key and Validate the json output given by the LLM."
      ],
      "metadata": {
        "id": "g048lk_m75jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a pydantic model for getting the exact strcutured json from the input query as we want\n",
        "class Candidate(BaseModel):\n",
        "    entity: str = Field(description=\"The company name mentioned in the query (e.g., Flipkart, Amazon).\")\n",
        "    parameter: str = Field(description=\"The performance metric mentioned in the query (e.g., GMV, revenue, profit)\")\n",
        "    startDate: str = Field(description=f\"The start date of the time period for which the metric is requested. By default,if the user query does not explicitly mention the start date.Assume Default start date to be : Today's date(is {datetime.today().date()}) minus one year.\")\n",
        "    endDate: str = Field(description=f\"The end date of the time period for which the metric is requested.By default If the user query does not explicitly mention the end date. Assume the end date to be : Today's date(is {datetime.today().date()}).\")"
      ],
      "metadata": {
        "id": "EnWO5LDKQdzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialising the OpenAI model , Please provide your valid OPENAI_API_KEY in the cell below in the first line"
      ],
      "metadata": {
        "id": "nouQlfyZ8lfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY=userdata.get(\"OPENAI_API_KEY\")\n",
        "model_name = \"gpt-3.5-turbo-instruct\"\n",
        "temperature = 0.0\n",
        "model = OpenAI(openai_api_key=API_KEY,model_name=model_name, temperature=temperature, max_tokens=800)"
      ],
      "metadata": {
        "id": "fmxkPt7BQtyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function responsible for taking the user query processing it and Validating it with Pydantic model keys and printing the Json output"
      ],
      "metadata": {
        "id": "-HAR29u287Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graphQL_template = \"\"\"\n",
        "\n",
        "The response should understand a user question and return a graphql query according to it.\n",
        "The Supabase table under consideration is named as \"receipt_radar_insights\" and it has the following column_names:\n",
        "purchaseCategories,competitorReceipts,shoppingDates,spendingCapacity\n",
        "The response must ONLY contain the code snippet and NOTHING else.\n",
        "The response must be one single line which contains only the query and must not be assigned to a variable.\n",
        "Example 1:\n",
        "Question: what's is previuous month budget ?\n",
        "Response:\n",
        "{\n",
        "  receipt_radar_insightsCollection\n",
        "{\n",
        "  edges\n",
        "{\n",
        "  node\n",
        "{shoppingDates spendingCapacity}\n",
        "\n",
        "}\n",
        "  }\n",
        "    }\n",
        "\n",
        "Example 2:\n",
        "Question: What did I spend on last month?\n",
        "Response:\n",
        "{\n",
        "  receipt_radar_insightsCollection\n",
        "{\n",
        "  edges\n",
        "{\n",
        "  node\n",
        "{purchaseCategories}\n",
        "\n",
        "}\n",
        "  }\n",
        "    }\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zl3cIg7Jlg3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bot_response(user_query,response_history):\n",
        "  try:\n",
        "    prompt = PromptTemplate(\n",
        "      template=\"Answer the user query based on the below examples and template.\\n{graphQL_template}\\n User Query :\\n {query} .\\n\\nMessage History:\\n{history}.\\n Above is your previous response.\",\n",
        "      input_variables=[\"query\"],\n",
        "      partial_variables={\"graphQL_template\": graphQL_template, \"history\": \"\\n\".join(str(list(response_history)))},\n",
        "    )\n",
        "    input = prompt.format_prompt(query=str(user_query))\n",
        "    print(input.to_string())\n",
        "    with get_openai_callback() as cb:\n",
        "      try:\n",
        "        result = model.invoke(input.to_string())\n",
        "        print(\"printing result\")\n",
        "        print(result)\n",
        "      except Exception as e:\n",
        "        print(f\"Error {e}\")\n",
        "\n",
        "      try:\n",
        "        print(\"saving history\")\n",
        "        response_history.append(result)\n",
        "        print(\"Bot: \",list(response_history))\n",
        "        return list(response_history)\n",
        "      except Exception as e:\n",
        "        print(f\"Error {e}\")\n",
        "        response_history.append(\"None\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error : {e}\")\n"
      ],
      "metadata": {
        "id": "SvbWwYH37c6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Below cell can be used for interaction , You can test your prompts here"
      ],
      "metadata": {
        "id": "NRzzkWhA9Il4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_history = deque(maxlen=4)\n",
        "while True:\n",
        "  user_query = input(\"User: \")\n",
        "  user_query = user_query\n",
        "  if user_query == \"exit\":\n",
        "    break\n",
        "  bot_response(user_query,message_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIuWSz3gm7oS",
        "outputId": "e78154a5-71f5-41be-b96e-2d1a442f33f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: what's is previuous month budget ?\n",
            "Answer the user query based on the below examples and template.\n",
            " \n",
            "\n",
            "The response should understand a user question and return a graphql query according to it.\n",
            "The Supabase table under consideration is named as \"receipt_radar_insights\" and it has the following column_names:\n",
            "purchaseCategories,competitorReceipts,shoppingDates,spendingCapacity\n",
            "The response must ONLY contain the code snippet and NOTHING else.\n",
            "The response must be one single line which contains only the query and must not be assigned to a variable.\n",
            "Example 1:\n",
            "Question: whats is previuous month budget ?\n",
            "Response:\n",
            "{\n",
            "  receipt_radar_insightsCollection\n",
            "{\n",
            "  edges\n",
            "{\n",
            "  node\n",
            "{shoppingDates spendingCapacity}\n",
            "\n",
            "}\n",
            "  }\n",
            "    }\n",
            "\n",
            "Example 2:\n",
            "Question: What did I spend on last month?\n",
            "Response:\n",
            "{\n",
            "  receipt_radar_insightsCollection\n",
            "{\n",
            "  edges\n",
            "{\n",
            "  node\n",
            "{purchaseCategories}\n",
            "\n",
            "}\n",
            "  }\n",
            "    }\n",
            "\n",
            "\n",
            " User Query :\n",
            " what's is previuous month budget ? .\n",
            "\n",
            "Message History:\n",
            "[\n",
            "].\n",
            " Above is your previous response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in OpenAICallbackHandler.on_llm_end callback: TypeError(\"unsupported operand type(s) for /: 'NoneType' and 'int'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing result\n",
            "\n",
            "saving history\n",
            "Bot:  ['']\n"
          ]
        }
      ]
    }
  ]
}